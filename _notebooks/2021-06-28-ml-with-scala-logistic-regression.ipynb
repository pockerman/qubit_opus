{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Scala Logistic Regression\n",
    "\n",
    "\n",
    "> \"Logistic regression with Scala\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [machine-learning, Scala, logistic-regression]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the post <a href=\"https://pockerman.github.io/qubit_opus/machine-learning/scala/linear-regression/2021/06/27/ml-with-scala-linear-regression.html\">Machine Learning with Scala Linear Regression</a> we saw how to develop a simple linear regressor with the aide of the <a href=\"https://github.com/scalanlp/breeze\">Breeze</a> library. In this post, we see how to develop a logistic regressor classifier for two class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Scala Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a linear classifier that is the decision boundary is a line or a hyperplane. The logistic regression algorithm  is to a large extent similar to linear regression with two notable differences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We filter the result of the linear regression so that it is mapped in the range $[0, 1]$. Thus, the immediate output of logistic regression can be interpreted as a probability\n",
    "- The loss function that we minimize is not the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than that the algorithm is the same. Hence, we use a linear model of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y}_i = a x_i + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we filter it via function so that the ouput is mapped bewteen $[0, 1]$. The <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\">sigmoid</a> function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\phi(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be used for such a filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function has the following form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\mathbf{w}) = \\sum_{i}^N -y_i log(\\hat{y}_i) + (1 - y_i)(1 - log(\\hat{y}_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{w}$ is the parameters coefficients with $\\mathbf{w} = [a, b]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import some useful packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import breeze.linalg.{DenseMatrix, DenseVector}\n",
    "import breeze.linalg._\n",
    "import breeze.numerics.{exp, log1p, sigmoid}\n",
    "import breeze.optimize.{DiffFunction, minimize}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the loss function and its gradient calculation into an ```object``` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "object LogisticRegression{\n",
    "\n",
    "  def L(x: DenseMatrix[Double], y: DenseVector[Double], \n",
    "        parameters: DenseVector[Double]): Double = {\n",
    "        \n",
    "    val xBeta = x * parameters\n",
    "    val expXBeta = exp(xBeta)\n",
    "    val targets_time = y *:* xBeta\n",
    "    -sum(targets_time - log1p(expXBeta))\n",
    "  }\n",
    "\n",
    "\n",
    "  def gradL(x: DenseMatrix[Double], y: DenseVector[Double], \n",
    "            parameters: DenseVector[Double]): DenseVector[Double]={\n",
    "            \n",
    "    val xBeta = x * parameters\n",
    "    val probs = sigmoid(xBeta)\n",
    "    x.t * (probs - y)\n",
    "  }\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the class that wraps the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "class LogisticRegression {\n",
    "\n",
    "  // The model parameters\n",
    "  var parameters: DenseVector[Double] = null\n",
    "\n",
    "  // Flag indicating if the interception term is used\n",
    "  var useIntecept: Boolean=true;\n",
    "\n",
    "  // auxiliary constructor\n",
    "  def this(numFeatures: Int, useIntercept: Boolean=true){\n",
    "    this()\n",
    "    init(numFeatures = numFeatures, useIntercept = useIntercept)\n",
    "  }\n",
    "\n",
    "  // initialize the underlying data\n",
    "  def init(numFeatures: Int, useIntercept: Boolean=true): Unit = {\n",
    "\n",
    "    val totalFeatures = if(useIntercept) numFeatures + 1 else numFeatures\n",
    "    this.parameters = DenseVector.zeros[Double](totalFeatures)\n",
    "    this.useIntecept = useIntercept\n",
    "  }\n",
    "\n",
    "  // train the model\n",
    "  def train(x: DenseMatrix[Double], y: DenseVector[Double])={\n",
    "\n",
    "    // set up the optimization\n",
    "    val f = new DiffFunction[DenseVector[Double]] {\n",
    "      def calculate(parameters: DenseVector[Double]) = (LogisticRegression.L(x, y, parameters=parameters),\n",
    "        LogisticRegression.gradL(x, y, parameters = parameters))\n",
    "    }\n",
    "\n",
    "    this.parameters = minimize(f, this.parameters)\n",
    "  }\n",
    "\n",
    "  // predict the class of the given point\n",
    "  def predict(x: DenseVector[Double]): Double = {\n",
    "\n",
    "    require(parameters != null)\n",
    "\n",
    "    if(!useIntecept){\n",
    "      require(x.size == parameters.size)\n",
    "      sum(parameters * x)\n",
    "    }\n",
    "    else{\n",
    "      require(x.size == parameters.size -1 )\n",
    "      sum(parameters.slice(0, x.size) * x) + parameters(0)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this into action with a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import breeze.linalg._\n",
    "import breeze.numerics._\n",
    "import breeze.optimize._\n",
    "import breeze.stats._\n",
    "import engine.models.LogisticRegression\n",
    "import engine.utils.{CSVDataSetLoader, VectorUtils}\n",
    "import spire.algebra.NormedVectorSpace.InnerProductSpaceIsNormedVectorSpace\n",
    "import spire.implicits.rightModuleOps\n",
    "\n",
    "object LogisticRegression_Exe extends App{\n",
    "\n",
    "  println(s\"Starting application: ${LogisticRegression_Exe.getClass.getName}\")\n",
    "\n",
    "  // load the data\n",
    "  val data = CSVDataSetLoader.loadRepHeightWeightsFullData\n",
    "  val recaledHeights = VectorUtils.standardize(data.heights);\n",
    "  val rescaledWeights = VectorUtils.standardize(data.weights);\n",
    "  val rescaledHeightsAsMatrix = recaledHeights.toDenseMatrix.t\n",
    "  val rescaledWeightsAsMatrix = rescaledWeights.toDenseMatrix.t\n",
    "\n",
    "  val featureMatrix = DenseMatrix.horzcat(DenseMatrix.ones[Double](rescaledHeightsAsMatrix.rows, 1),\n",
    "    rescaledHeightsAsMatrix, rescaledWeightsAsMatrix)\n",
    "\n",
    "  println(s\"Feature matrix shape (${featureMatrix.rows}, ${featureMatrix.cols})\")\n",
    "\n",
    "  val targets = data.genders.values.map{gender => if(gender == 'M') 1.0 else 0.0}\n",
    "\n",
    "  println(s\"Targets vector shape (${targets.size}, )\")\n",
    "\n",
    "  // logistic regression model\n",
    "  val lr = new LogisticRegression;\n",
    "\n",
    "  // initialize the model\n",
    "  lr.init(numFeatures=2)\n",
    "  lr.train(x=featureMatrix, y=targets)\n",
    "\n",
    "  val optimalParams = lr.parameters\n",
    "  println(s\"Optimal parameters ${optimalParams}\")\n",
    "  println(\"Done...\")\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the complete example in this <a href=\"https://github.com/pockerman/scala_ml\">repo</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we looked into how to develop a simple linear regression model with Scala. The Scala numerics library <a href=\"https://github.com/scalanlp/breeze\">Breeze</a> greatly simplifies the development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://en.wikipedia.org/wiki/Logistic_regression#:~:text=Logistic%20regression%20is%20a%20statistical,a%20form%20of%20binary%20regression).\">Logistic regression</a>\n",
    "2. Pascal Bugnion, Patric R. Nicolas, Alex Kozlov, ```Scala: Applied Machine Learning```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
