{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Object Communication 1\n",
    "\n",
    "\n",
    "> \"Create derived data types with MPI_Type_create_struct\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [programming, MPI, parallel-computing, C++]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In object oriented code bases, data is typically organized into classes that wrap functionality, hide information and expose an API so that client code can utilize them. Thus, frequently, we end up in the situation where we have an object that we need to send across. MPI offers various posibilities to do so. In this post we will see  ```MPI_Type_create_struct```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a> MPI Object Communication 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI communication functions such as ```MPI_Send/Recv``` need as an input the type of the data that is to be communicated [1]. When dealing with primitive types like integers and floats MPI has got us covered so there isn't much we should do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, frequently we want to communicate structures or objects. Sure, we can break up the structures\n",
    "that need to be communicated into individual elements or arrays of elements and send these\n",
    "in a series of send operations. However, this costly and rather counter productive; it breaks data encapsulation to start with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why it is costly, can be understood by considerin the so-called start-up latency [1]. This is the fixed cost we need to accept that includes the activation of multiple\n",
    "OS layers, the network interface, and so on [1]. The result is that although the actual over-the-wire\n",
    "times may be identical, the accumulation of the extra start-up latencies makes such an approach expensive to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI has two main mechanisms that we can use to communicate structures between\n",
    "heterogeneous machines [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MPI derived datatypes\n",
    "- Packing/unpacking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we will look into how to construct MPI derived datatypes using  ```MPI_Type_create_struct``` and leave the second approach for another post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory layout of the same data structure differs from machine to machine. MPI, in order to successfully transfer and  translate   an instance of a structure from one machine to another, it requires the following information [1]: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number and types of all the data members/fields.\n",
    "- The relative offset of the fields from the beginning of the structure (where to deposit data).\n",
    "- The total memory occupied by a structure, including any padding necessary to align it to specific boundaries. This is needed so that arrays of structures can be communicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI provides utilities for describing the \n",
    "information above for a generatl datatype. Once a derived datatype is defined, a reference to this object can be used in any communication function that requires a datatype specification parameter [1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Remark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derived datatypes must be declared individually/locally in all the processes that will\n",
    "employ them [1].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the most commonly used functions for creating derived datatypes are [1]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```MPI_Type_vector```\n",
    "- ```MPI_Type_create_struct```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MPI_Type_vector``` is useful  for\n",
    "extracting blocks of data from single or multidimensional arrays of a single datatype e.g. a vector.\n",
    "```MPI_Type_create_struct``` is the most generic of the available functions,\n",
    "allowing the use of blocks made of different datatypes [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the approach used, each specification of a derived datatype must be followed by a call to the\n",
    "```MPI_Type_commit``` function for having MPI store the specification internally. Once\n",
    "a datatype is committed, it can be used repeatedly in communication functions.\n",
    "```MPI_Type_commit``` takes just a single parameter, which is a reference to the\n",
    "```MPI_Datatype``` object [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows how to use ```MPI_Type_create_struct```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include <mpi.h>\n",
    "#include <iostream>\n",
    "\n",
    "\n",
    "struct Point\n",
    "{\n",
    " unsigned int id;\n",
    " double x;\n",
    " double y;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned  ```MPI_Type_create_struct``` is rather involved so we group everything in the following function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "void create_mpi_point(\tMPI_Datatype* t){\n",
    "\n",
    "\tPoint p;\n",
    "\t\n",
    "\t// the types the struct has\n",
    "\tMPI_Datatype types [3];\n",
    "\t\n",
    "\ttypes[0] = MPI_UNSIGNED;\n",
    "\ttypes[1] = MPI_DOUBLE;\n",
    "\ttypes[2] = MPI_DOUBLE;\n",
    "\t\n",
    "\t// get the addresses\n",
    "\tMPI_Aint displ[3];\n",
    "\tMPI_Aint off; \n",
    "\tMPI_Aint base;\n",
    "\t\n",
    "\tdispl [0] = 0 ;\n",
    "\t\n",
    "\tMPI_Get_address (&(p.id) , &base ) ;\n",
    "\tMPI_Get_address (&(p.x) , &off ) ;\n",
    "\tdispl [1] = off- base ;\n",
    "\tMPI_Get_address (&(p.y) , &off ) ;\n",
    "\tdispl [2] = off - base;\n",
    "\t\n",
    "\tint blklen [3] = {1, 1, 1} ;\n",
    "\t\n",
    "\t// create the type\n",
    "\tMPI_Type_create_struct( 3 , blklen , displ , types , t);\n",
    "\t\n",
    "\t// commit it\n",
    "\tMPI_Type_commit ( t ) ;\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "\tint rank;\n",
    "\tint n_procs;\n",
    "\t\n",
    "\t// initialize MPI. No MPI calls\n",
    "\t// prior to this point should be made\n",
    "\tMPI_Init(&argc, &argv);\n",
    "\t\n",
    "\t// what's my rank\n",
    "\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\t\n",
    "\t// how may procs\n",
    "\tMPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n",
    "\t\n",
    "\tif(n_procs > 2){\n",
    "\t\tstd::cout<<\"Application should be run with 2 processes.\"<<std::endl;\n",
    "\t\tMPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);\n",
    "\t}\n",
    "\t\n",
    "\t// status on the receive side\n",
    "\tMPI_Status status;\n",
    "\t\n",
    "\t// all processes must commit the Point type\n",
    "\tMPI_Datatype mpi_point_type;\n",
    "\t\n",
    "\t// create the mpi point\n",
    "\tcreate_mpi_point(&mpi_point_type);\n",
    "\t\n",
    "\tif(rank == 0){\n",
    "\t\n",
    "\t\tstd::cout<<\"Hello from process \"<<rank<<\" of \"<<n_procs<<std::endl;\n",
    "\t\t\n",
    "\t\tPoint p = {10, 0.5, 1.5};\n",
    "\t\t\n",
    "\t\tstd::cout<<\"Process \"<<rank<<\" sending point \"\n",
    "\t\t         <<p.id\n",
    "\t\t         <<\", \"\n",
    "\t\t         <<p.x\n",
    "\t\t         <<\", \"\n",
    "\t\t         <<p.y\n",
    "\t\t         <<std::endl;\n",
    "\t\t\n",
    "\t\t// send a number to the worker \n",
    "\t\tMPI_Send(&p, 1, mpi_point_type, 1, 0, MPI_COMM_WORLD);\n",
    "\t\t\t\n",
    "\t}\n",
    "\telse if(rank == 1){\n",
    "\t\n",
    "\t\t// receive \n",
    "\t\tPoint p_recv;\n",
    "\t\t\n",
    "\t\tMPI_Recv(&p_recv, 1, mpi_point_type, 0, 0, MPI_COMM_WORLD, &status);\n",
    "\t\t\n",
    "\t\tstd::cout<<\"Process \"<<rank<<\" received point \"\n",
    "\t\t         <<p_recv.id\n",
    "\t\t         <<\", \"\n",
    "\t\t         <<p_recv.x\n",
    "\t\t         <<\", \"\n",
    "\t\t         <<p_recv.y\n",
    "\t\t         <<std::endl;\n",
    "\t\t\t\n",
    "\t}\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tMPI_Finalize();\n",
    "\t// No MPI calls beyond this point\n",
    "\t\n",
    "\treturn 0;\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"summary\"></a> Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this post breifly touched on the issued of communicating user defined datatypes with MPI. These are usually in the form of classes or structs. Although, we could align such types with primitive types and comunicate the ensuing arrays, this is not a viable approach due to start-up latency. Furthermore, it will certainly lead to an error prone and complex code base. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI provides various utilites in order to address such a situation. In this post, we saw  ```MPI_Type_create_struct```. This is the most generic of the available functions,\n",
    "allowing the use of blocks made of different datatypes [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gerassimos Barlas, ```Multicore and GPU Programming. An Integrated Approach```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
