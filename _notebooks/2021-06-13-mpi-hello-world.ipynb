{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Hello World\n",
    "\n",
    "> \"Hello World with MPI\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [programming, MPI, parallel-computing, C++]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a>  Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Message Passage Interface, MPI, is perhaps the defacto standard used in nowadays scientific distributed computing. It provides interfaces for both point-to-point and collective communication. In this series, we will go over basic and intermediate usage of the MPI standard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a>  MPI Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI is by now a well-established standard that includes [1]: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process creation \n",
    "- Process management\n",
    "- Point-to-point communication\n",
    "- Collective communication\n",
    "- One-sided communication\n",
    "- External interfaces\n",
    "- Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language bindings exist for C and Fortran. Newer MPI standards are trying to better support the scalability in future extreme-scale computing systems, because currently, the only feasible option for increasingthe computing power is to increase the number of cooperating processors [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet is the ```Hello World``` equivalent for MPI. It demonstrates basic usage of the standard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "// example_1.cpp\n",
    "\n",
    "#include <mpi.h>\n",
    "#include <iostream>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "\tint rank;\n",
    "\tint n_procs;\n",
    "\t\n",
    "\t// initialize MPI. No MPI calls\n",
    "\t// prior to this point should be made\n",
    "\tMPI_Init(&argc, &argv);\n",
    "\t\n",
    "\t// what's my rank\n",
    "\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\t\n",
    "\t// how may procs\n",
    "\tMPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n",
    "\t\n",
    "\tstd::cout<<\"Hello from process \"<<rank<<\" of \"<<n_procs<<std::endl;\n",
    "\t\n",
    "\tMPI_Finalize();\n",
    "\t// No MPI calls beyond this point\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compile the code by using the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mpicxx example_1.cpp -o example_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing using four processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mpirun -np 4 example_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Hello from process 0 of 4\n",
    "Hello from process 1 of 4\n",
    "Hello from process 3 of 4\n",
    "Hello from process 2 of 4\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Remark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```mpirun``` command is also known as ```mpiexec``` on some implementations.  It makesl  that copies of the executable can be run on every machine.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to access any MPI  related functionality we need to inlude the header file ```mpi.h````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MPI related functions start with the prefix ```MPI_```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As commented in the code, all MPI related calls should occur within ```MPI_Init/MPI_Finalize```. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, wevery process executes the same instructions. We can use ```if/else``` statements to differentiate what each process will execute. The variable ```MPI_COMM_WORLD``` represents the default  communication group in the statndard. It involves all the processes running the current calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above also calculates the rank of the calling process via ```MPI_Comm_rank```, and the total number of processes in the comunicator ```MPI_Comm_size```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Roman Trobec et al., ```Introduction to parallel computing. From algorithms to programming on state-of-the-art platforms```, Springer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
