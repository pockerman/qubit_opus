{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch with C++ 1\n",
    "\n",
    "> \"PyTorch with C++\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [pytorch, deep-neural-networks, API, c++, numerics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pytorch.org/\">PyTorch</a> is one of the well established libraries for modeling deep neural networks. The exposed Python API is the most commonly used one. However, the library also exposes bindings for C++. In this series of notebooks, I will try to demonstrate how to use the latter. I will be following to a large extent the documentation for the C++ frontend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch with C++ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by performing some basic manipulations with the ```Tensor``` class. Instances of this class are used around the library to perform numerics. Whilst at this I will also show how to link against the C++ bindings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and link against ```libtorch```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, download the binaries from here: https://pytorch.org/get-started/locally/. I use the pre-build binaries. Also make sure that you download the C++11 ABI.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create now the first C++ PyTorch program. The following program is taken from the official documentation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include <torch/torch.h>\n",
    "#include <iostream>\n",
    "\n",
    "int main() {\n",
    "  torch::Tensor tensor = torch::eye(3);\n",
    "  std::cout << tensor << std::endl;\n",
    "  return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I  use the following ```CMakeLists.txt``` file to generate the needed ```Makefile```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n",
    "\n",
    "PROJECT(example_1 VERSION 1.0.0 LANGUAGES CXX)\n",
    "SET(SOURCE example_1.cpp)\n",
    "SET(EXECUTABLE  example_1)\n",
    "\n",
    "# default optionsSET(BUILD_SHARED_LIBS ON)\n",
    "SET(CMAKE_BUILD_TYPE \"Debug\")\n",
    "SET(CMAKE_CXX_COMPILER g++)\n",
    "SET(CMAKE_CXX_STANDARD 20)\n",
    "SET(CMAKE_CXX_STANDARD_REQUIRED True)\n",
    "SET(CMAKE_C_COMPILER gcc)\n",
    "SET(CMAKE_LINKER_FLAGS \"-pthread\")\n",
    "\n",
    "\n",
    "LIST(APPEND CMAKE_PREFIX_PATH /home/alex/MySoftware/libtorch)\n",
    "FIND_PACKAGE(Torch REQUIRED CONFIG)\n",
    "MESSAGE(STATUS \"TORCH Include directory ${TORCH_INCLUDE_DIRS}\")\n",
    "\n",
    "MESSAGE(STATUS \"Build type: ${CMAKE_BUILD_TYPE}\")\n",
    "MESSAGE(STATUS \"C++ Compiler: ${CMAKE_CXX_COMPILER}\")\n",
    "MESSAGE(STATUS \"C Compiler: ${CMAKE_C_COMPILER}\")\n",
    "\n",
    "\n",
    "INCLUDE_DIRECTORIES(${TORCH_INCLUDE_DIRS})\n",
    "\n",
    "ADD_EXECUTABLE(${EXECUTABLE} ${SOURCE})\n",
    "TARGET_LINK_LIBRARIES(${EXECUTABLE} ${TORCH_LIBRARIES})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program above produces the following output when built and executed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 1  0  0\n",
    " 0  1  0\n",
    " 0  0  1\n",
    "[ CPUFloatType{3,3} ]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now extend the example above to check on the provided API. Still, this is very elementary. Here is the updated example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include <torch/torch.h>\n",
    "\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "\n",
    "int main() {\n",
    "\n",
    "\n",
    "  if(torch::cuda::is_available()){\n",
    "  \tstd::cout<<\"CUDA is available on this machine\"<<std::endl;\n",
    "  }\n",
    "  else{\n",
    "  \tstd::cout<<\"CUDA is not available on this machine\"<<std::endl;\n",
    "  }\n",
    "\n",
    "  torch::Tensor tensor = torch::eye(3);\n",
    "  std::cout << tensor << std::endl;\n",
    "  \n",
    "  std::vector<double> data(3, 2.0);\n",
    "  auto tensor_from_data_1 = torch::tensor(data);\n",
    "  std::cout << tensor_from_data_1 << std::endl; \n",
    "  \n",
    "  data[0] = data[1] = data[2] = 1.0;\n",
    "  auto tensor_from_data_2 = torch::tensor(data);\n",
    "  std::cout << tensor_from_data_2 << std::endl; \n",
    "  \n",
    "  auto sum = tensor_from_data_2 + tensor_from_data_1;\n",
    "  std::cout << sum << std::endl;\n",
    "    \n",
    "    \n",
    "  if(torch::cuda::is_available()){\n",
    "  \n",
    "   // create a tensor and send it to the GPU\n",
    "   auto cuda_tensor = torch::tensor({1.0, 2.0, 3.0}).to(\"cuda\");\n",
    "   \n",
    "  }\n",
    "  \n",
    "  // compute element-wise product\n",
    "  auto tensor1 = torch::tensor({1.0, 2.0, 3.0});\n",
    "  auto product = tensor1 * tensor1;\n",
    "  std::cout << product << std::endl; \n",
    "  return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the program above is shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CUDA is not available on this machine\n",
    " 1  0  0\n",
    " 0  1  0\n",
    " 0  0  1\n",
    "[ CPUFloatType{3,3} ]\n",
    " 2\n",
    " 2\n",
    " 2\n",
    "[ CPUFloatType{3} ]\n",
    " 1\n",
    " 1\n",
    " 1\n",
    "[ CPUFloatType{3} ]\n",
    " 3\n",
    " 3\n",
    " 3\n",
    "[ CPUFloatType{3} ]\n",
    " 1\n",
    " 4\n",
    " 9\n",
    "[ CPUFloatType{3} ]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The driver code above can be found in this <a href=\"https://github.com/pockerman/pyttoch_cpp_examples\">github repository</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href=\"https://pytorch.org/\">PyTorch</a>\n",
    "- <a href=\"https://pytorch.org/tutorials/advanced/cpp_frontend.html\">Using the PyTorch C++ Frontend</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
