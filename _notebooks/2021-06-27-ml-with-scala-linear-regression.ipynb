{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Scala: Linear Regression\n",
    "\n",
    "\n",
    "> \"Linear regression with Scala\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [machine-learning, Scala, linear-regression]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python at the time of writing is the defacto language for prototyping and developing machine learning algorithms. In this post, we will be using Scala to develop a simple linear regressor model. We will do this with the help of the Scala numerics library <a href=\"https://github.com/scalanlp/breeze\">Breeze</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML with Scala: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is well known, the linear regression model assumes the following functional form for the predictor $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y}_i = a x_i + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function has the following form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\mathbf{w}) = \\sum_{i}^N (y_i - \\hat{y}_i)^2 = \\sum_{i}^N (y_i - (a x_i + b))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{w}$ is the parameters coefficients with $\\mathbf{w} = [a, b]$. The gradient of the loss function with respect to the parameters is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial a} = -2 \\sum_{i}^N (y_i - \\hat{y}_i) x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L}{\\partial b} = -2 \\sum_{i}^N (y_i - \\hat{y}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import some useful packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import breeze.linalg._\n",
    "import breeze.optimize.{DiffFunction, minimize}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the loss function and its gradient calculation into an ```object``` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "object LinearRegression\n",
    "{\n",
    "  def L(x: DenseMatrix[Double], y: DenseVector[Double], parameters: DenseVector[Double]): Double = {\n",
    "    val yHat = x * parameters\n",
    "    var value = 0.0\n",
    "    for( i <- 0 until yHat.size){\n",
    "      val diff =  y(i) - yHat(i)\n",
    "      value += diff * diff\n",
    "    }\n",
    "    value\n",
    "  }\n",
    "\n",
    "\n",
    "  def gradL(x: DenseMatrix[Double], y: DenseVector[Double], parameters: DenseVector[Double]): DenseVector[Double]={\n",
    "\n",
    "\n",
    "    val yHat = x * parameters\n",
    "\n",
    "    // we have as many components as columns\n",
    "    val gradients = DenseVector.zeros[Double](x.cols)\n",
    "\n",
    "    for( i <- 0 until yHat.size){\n",
    "      var diff =  y(i) - yHat(i)\n",
    "\n",
    "      for( c <- 0 until gradients.size){\n",
    "         diff *= x(i, c)\n",
    "         gradients(c) += diff\n",
    "      }\n",
    "    }\n",
    "    -2.0 * gradients\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the class that wraps the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "class LinearRegression{\n",
    "\n",
    "  // The model parameters\n",
    "  var parameters: DenseVector[Double] = null\n",
    "\n",
    "  // Flag indicating if the interception term is used\n",
    "  var useIntecept: Boolean=true;\n",
    "  \n",
    "  // constructor\n",
    "  def this(numFeatures: Int, useIntercept: Boolean=true){\n",
    "    this()\n",
    "    init(numFeatures = numFeatures, useIntercept = useIntercept)\n",
    "  }\n",
    "\n",
    " \n",
    "  // train the model\n",
    "  def train(x: DenseMatrix[Double], y: DenseVector[Double])={\n",
    "\n",
    "    // set up the optimization\n",
    "    val f = new DiffFunction[DenseVector[Double]] {\n",
    "      def calculate(parameters: DenseVector[Double]) = (LinearRegression.L(x, y, parameters=parameters),\n",
    "        LinearRegression.gradL(x, y, parameters = parameters))\n",
    "    }\n",
    "\n",
    "    this.parameters = minimize(f, this.parameters)\n",
    "    \n",
    "  }\n",
    "\n",
    "  // the initialization function\n",
    "  def init(numFeatures: Int, useIntercept: Boolean=true): Unit = {\n",
    "\n",
    "    val totalFeatures = if(useIntercept) numFeatures + 1 else numFeatures\n",
    "    this.parameters = DenseVector.zeros[Double](totalFeatures)\n",
    "    this.useIntecept = useIntercept\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this into action with a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "object LinearRegressionExe_1 {\n",
    "\n",
    "  // Split the interval [start, end] into nPoints\n",
    "  def lineSplit(start: Double, end: Double, nPoints: Int): DenseVector[Double] ={\n",
    "\n",
    "    require(end > start)\n",
    "    require(nPoints > 0)\n",
    "\n",
    "    val points = DenseVector.zeros[Double](nPoints)\n",
    "\n",
    "    val dx = (end - start)/nPoints\n",
    "\n",
    "    for(i <- Range(0, nPoints)){\n",
    "      points(i) = start + i*dx\n",
    "    }\n",
    "\n",
    "    points(points.size -1) = end\n",
    "    points\n",
    "  }\n",
    "  \n",
    "  // Split the interval [start, end] into nPoints\n",
    "  def polynomial(x: DenseVector[Double], a: Double, b: Double): DenseVector[Double] ={\n",
    "\n",
    "    val y = DenseVector.zeros[Double](x.size)\n",
    "\n",
    "    for(i <- Range(0, x.size)){\n",
    "      y(i) = a * x(i) + b\n",
    "    }\n",
    "\n",
    "    y\n",
    "  }\n",
    "\n",
    "\n",
    "  def main(args: Array[String]):Unit={\n",
    "\n",
    "    // data set\n",
    "    val x = lineSplit(0.0, 10.0, 100)\n",
    "\n",
    "\n",
    "    System.out.println(\"Number of training examples: \" + x.size)\n",
    "    \n",
    "    val a = 2.0\n",
    "    val b = 1.0\n",
    "    val y = polynomial(x, a=a, b=b)\n",
    "\n",
    "    // the feature matrix\n",
    "    val featureMatrix = DenseMatrix.horzcat(DenseMatrix.ones[Double](x.size, 1), x.toDenseMatrix.t)\n",
    "\n",
    "    // model\n",
    "    val model = new LinearRegression(numFeatures = 1, useIntercept = true)\n",
    "\n",
    "    model.train(x=featureMatrix,y=y)\n",
    "\n",
    "    println(s\"Polynomial coeffs a=${a}, b=${b}\")\n",
    "    println(s\"Linear regressor coeffs ${model.getParameters}\")\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"summary\"></a> Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we looked into how to develop a simple linear regression model with Scala. The Scala numerics library <a href=\"https://github.com/scalanlp/breeze\">Breeze</a> greatly simplifies the development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://en.wikipedia.org/wiki/Linear_regression\">Linear regression</a>\n",
    "2. Pascal Bugnion, Patric R. Nicolas, Alex Kozlov, ```Scala: Applied Machine Learning```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
