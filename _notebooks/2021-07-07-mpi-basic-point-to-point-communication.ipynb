{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Basic Point-to-Point Communication\n",
    "\n",
    "> \"Basic point-to-point communication with MPI\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [programming, MPI, parallel-computing, C++]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When two processes communicate with each other, we call this communication pattern as point-to-point communication [3]. MPI allows for easy information exchange between processes or nodes although the resulting interfaces may be quite overwhelming. In this notebook, we introduce the two most basic point-to-point communication functions in MPI namely ```MPI_Send``` (<a href=\"https://www.mpich.org/static/docs/latest/www3/MPI_Send.html\">doc</a>) and ```MPI_Recv``` (<a href=\"https://www.mpich.org/static/docs/latest/www3/MPI_Recv.html\">doc</a>). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a> Basic point-to-point Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MPI_Send``` performs a blocking send; that is the function call may block until the message is received by the destination process [1]. An ```MPI_Send``` must be matched with a receive operation. ```MPI_Recv``` (<a href=\"https://www.mpich.org/static/docs/latest/www3/MPI_Recv.html\">doc</a>) performs a blocking receive [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Remark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```MPI_Send```  may return before the message is delivered. ```MPI_Send``` uses the so called **standard communication mode** [3]. Behind the scenes, MPI decides whether to block or not based on the size of the message. The blocking lasts until the the destination process collects the message. Thus, if the message is small ```MPI_Send``` returns as soon as the message is copied to a local MPI buffer [3]. This copy is needed in order to release the buffer used by\n",
    "the source process for subsequent operations, because with this form of send, there\n",
    "is no way for the sender process to know when the message has been delivered [3].\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MPI_Send```  sends a buffer of data of a certain type to another process. It requires the following arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A pointer to a data buffer\n",
    "- The datatype contained in the specified data buffer\n",
    "- How many elements are contained in the buffer \n",
    "- A message tag (sort of the id of the message) which should be a non-negative integer\n",
    "- The receiving process id wihin the communicator\n",
    "- The communicator used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype must correspond precisely to the data stored in the buffer. For this, MPI has predefined types that can be used. MPI has most of the usual C types. Furthermore, the standard has made provisions for creating and communicating user defined types as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that ```MPI_Send``` returns an error value code. If this value is 0 (or the symbolic constant ```MPI_SUCCESS``` ), no error has occurred [3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Remark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behaviour when a fatal error occurs in any of the participating processes is to abort the whole execution. In a sense, the default MPI behaviour when an error occurs is not fault tolerant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MPI_Recv``` has a very similar signature with ```MPI_Send```. The exception is that there is no destination id parameter but the id of the process from the process receives. Note also that the buffer set aside must be at least as large as the number or elements expected to be received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specification of the sent/received datatype is required so that machines wiht different <a href=\"https://en.wikipedia.org/wiki/Endianness#:~:text=Endianness%20is%20primarily%20expressed%20as,significant%20byte%20at%20the%20largest.&text=Larger%20groups%20comprise%20two%20or,bit%20word%20contains%20four%20bytes.\">endianness</a> or machines with different memory types (32-bit, 64-bit, 128-bit) to be able to communicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"example\"></a> Simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example of how to use ```MPI_Send``` and ```MPI_Recv```. You can also find the example <a href=\"https://github.com/pockerman/mpi_playground/blob/master/example_2.cpp\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include <mpi.h>\n",
    "#include <iostream>\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "\tint rank;\n",
    "\tint n_procs;\n",
    "\t\n",
    "\t// initialize MPI. No MPI calls\n",
    "\t// prior to this point should be made\n",
    "\tMPI_Init(&argc, &argv);\n",
    "\t\n",
    "\t// what's my rank\n",
    "\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\t\n",
    "\t// how may procs\n",
    "\tMPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n",
    "\t\n",
    "\tMPI_Status status;\n",
    "\tif(rank == 0){\n",
    "\t\n",
    "\t\tstd::cout<<\"Hello from process \"<<rank<<\" of \"<<n_procs<<std::endl;\n",
    "\t\tint num = 2;\n",
    "\t\t\n",
    "\t\t// send a number to the worker \n",
    "\t\tMPI_Send(&num, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
    "\t\t\n",
    "\t\t// recv the answer\n",
    "\t\tint ans = -1;\n",
    "\t\tMPI_Recv(&ans, 1, MPI_INT, 1, 1, MPI_COMM_WORLD, &status);\n",
    "\t\t\n",
    "\t\tif(ans == 0){\n",
    "\t\t\tstd::cout<<\"Number \"<<num<<\" is odd\"<<std::endl;\t\t\n",
    "\t\t}\n",
    "\t\telse{\n",
    "\t\t\n",
    "\t\t\tstd::cout<<\"Number \"<<num<<\" is even\"<<std::endl;\n",
    "\t\t}\n",
    "\t}\n",
    "\telse if(rank == 1){\n",
    "\t\n",
    "\t\t// receive \n",
    "\t\tint data = -1;\n",
    "\t\t\n",
    "\t\tMPI_Recv(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n",
    "\t\t\n",
    "\t\tif(data % 2 == 0){\n",
    "\t\t\tdata = 1;\n",
    "\t\t\tMPI_Send(&data, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\t\t\n",
    "\t\t}\n",
    "\t\telse{\n",
    "\t\t\n",
    "\t\t\tdata = 0;\n",
    "\t\t\tMPI_Send(&data, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n",
    "\t\t}\n",
    "\t}\n",
    "\t\n",
    "\tMPI_Finalize();\n",
    "\t// No MPI calls beyond this point\n",
    "\t\n",
    "\treturn 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The tag can be any integer between 0-32767\n",
    "- ```MPI Recv``` may use for the tag the wildcard ```MPI_ANY_TAG```. This allows an ```MPI_Recv``` to receive from a send using any tag.\n",
    "- ```MPI_Send``` cannot use the wildcard ```MPI_ANY_TAG```. A speciﬁc tag must be speciﬁed.\n",
    "- ```MPI_Recv``` may use for the source the wildcard ```MPI_ANY_SOURCE```. This allows an ```MPI_Recv``` to receive from a send from any source.\n",
    "- ```MPI_Send``` must specify the process rank of the destination. No wildcard exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"summary\"></a> Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we introduced the two most basic point-to-point communication functions available in MPI. Namly we saw, ```MPI_Send``` and ```MPI_Recv```. Although these functions, and MPI in general, hide much of the boilerplate code needed so that two processes can communicate, still the resulting program is rather verbose. This is something that we would like to hide as much as possible both for application maintenance as well as for development and performance considerations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://www.mpich.org/static/docs/latest/www3/MPI_Send.html\">MPI_Send</a>\n",
    "2. <a href=\"https://www.mpich.org/static/docs/latest/www3/MPI_Recv.html\">MPI_Recv</a>\n",
    "3. Gerassimos Barlas, ```Multicore and GPU Programming An Integrated Approach```, Morgan Kaufmann"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
