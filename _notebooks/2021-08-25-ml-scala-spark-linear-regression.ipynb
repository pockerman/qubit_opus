{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning with Scala Spark linear regression\n",
    "\n",
    "> \"How to do linear regression with Spark in a Scala application\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [Spark, Scala, API, data-analysis, machine-learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a <a href=\"https://pockerman.github.io/qubit_opus/machine-learning/scala/linear-regression/2021/06/27/ml-with-scala-linear-regression.html\">previous post</a> I developed a trivial Scala application that performs linear regression with only one feature. In this post, I want to go a bit further, I want to use Spark's <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">MLlib</a> to develop a linear regression model using  two features this time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning with Scala Spark linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I need to do in order to use MLlib in my Scala application is to update the dependencies in the \n",
    "```build.sbt``` script. These should now look as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "libraryDependencies += \"org.apache.spark\" % \"spark-core_2.12\" % \"3.0.1\"\n",
    "libraryDependencies += \"org.apache.spark\" % \"spark-sql_2.12\" % \"3.0.1\"\n",
    "libraryDependencies += \"org.apache.spark\" % \"spark-mllib_2.12\" % \"3.0.1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "package train.spark\n",
    "\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.sql.types.DoubleType\n",
    "\n",
    "\n",
    "object LinearRegressionApp {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    \n",
    "    val conf = new SparkConf().setAppName(\"Linear regression Spark\")\n",
    "    val sc = new SparkContext(conf)\n",
    "    \n",
    "    val session = SparkSession.builder().appName(\"Linear regression Spark\").master(\"local[4]\").getOrCreate()\n",
    "    \n",
    "    // Should be some file on your system\n",
    "    val csvFile = \"/home/alex/qi3/spark_scala/data/spark_regression.csv\" \n",
    "    val inputTrainigSet = session.read.format(\"csv\").load(csvFile)\n",
    "        \n",
    "    println(\"Number of Partitions: \"+inputTrainigSet.rdd.getNumPartitions)\n",
    "    println(\"Action: First element: \"+inputTrainigSet.rdd.first()) \n",
    "   \n",
    "   val analysisData  = inputTrainigSet.withColumn(\"x1\", inputTrainigSet(\"_c0\").cast(DoubleType))\n",
    "                                      .withColumn(\"x2\", inputTrainigSet(\"_c1\").cast(DoubleType))\n",
    "                                      .withColumn(\"y\",  inputTrainigSet(\"_c2\").cast(DoubleType)) \n",
    "                                      .drop(\"_c0\")\n",
    "                                      .drop(\"_c1\")\n",
    "                                      .drop(\"_c2\")\n",
    "   \n",
    "    \n",
    "   //creating features column\n",
    "   val assembler = new VectorAssembler()\n",
    "  \t\t\t.setInputCols(Array(\"x1\",\"x2\"))\n",
    "  \t\t\t.setOutputCol(\"features\")\n",
    "    \n",
    "    // create the model\n",
    "    val lr = new LinearRegression()\n",
    "  \t\t.setMaxIter(10)\n",
    "  \t\t.setRegParam(0.3)\n",
    "  \t\t.setElasticNetParam(0.8)\n",
    "  \t\t.setFeaturesCol(\"features\")\n",
    "  \t\t.setLabelCol(\"y\")\n",
    "  \t\t\n",
    "   val trainigSet = assembler.transform(analysisData)\n",
    "  \t\t\n",
    "   // Fit the model\n",
    "   val lrModel = lr.fit(trainigSet)\n",
    "\n",
    "  // Print the coefficients and intercept for linear regression\n",
    "  println(s\"Coefficients: ${lrModel.coefficients} Intercept: ${lrModel.intercept}\")\n",
    "\n",
    "  // Summarize the model over the training set and print out some metrics\n",
    "  val trainingSummary = lrModel.summary\n",
    "  \n",
    "  println(s\"numIterations: ${trainingSummary.totalIterations}\")\n",
    "  \n",
    "  // there is sth wrong with my scala/spark version and this\n",
    "  // throws an excpetion\n",
    "  //println(s\"objectiveHistory: [${trainingSummary.objectiveHistory.mkString(\",\")}]\")\n",
    "  \n",
    "  trainingSummary.residuals.show()\n",
    "  println(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\n",
    "  println(s\"r2: ${trainingSummary.r2}\")\n",
    "}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "21/08/25 12:36:15 WARN Utils: Your hostname, LT-2R0620-101 resolves to a loopback address: 127.0.1.1; using 192.168.0.71 instead (on interface wlp58s0)\n",
    "21/08/25 12:36:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
    "WARNING: An illegal reflective access operation has occurred\n",
    "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/alex/MySoftware/spark-3.0.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
    "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
    "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
    "WARNING: All illegal access operations will be denied in a future release\n",
    "21/08/25 12:36:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "21/08/25 12:36:17 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.\n",
    "Number of Partitions: 1\n",
    "Action: First element: [0.0,4.0,4.357400305044133]\n",
    "21/08/25 12:36:22 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
    "21/08/25 12:36:22 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
    "Coefficients: [1.2545846367230242,0.7527507820338242] Intercept: 1.305736977601481\n",
    "numIterations: 3\n",
    "+--------------------+\n",
    "|           residuals|\n",
    "+--------------------+\n",
    "| 0.04066019930735543|\n",
    "| -0.6631570819021908|\n",
    "|  0.8844468485401586|\n",
    "|-0.27725408848247746|\n",
    "|   1.523792089069631|\n",
    "|  0.9081058052618962|\n",
    "|  0.6154843963633212|\n",
    "| -1.5426210882366824|\n",
    "|  -1.116750516169644|\n",
    "| -0.5438006575317718|\n",
    "|-0.41191237820348237|\n",
    "|-0.10423573938951769|\n",
    "| -0.7720329729420263|\n",
    "| -0.5175509972153742|\n",
    "|  0.5066514385552212|\n",
    "| 0.28386941829179424|\n",
    "| -1.7266735995448794|\n",
    "| -0.7963013580643907|\n",
    "| -0.8306208671329927|\n",
    "| -0.7913153349720496|\n",
    "+--------------------+\n",
    "only showing top 20 rows\n",
    "\n",
    "RMSE: 1.0241722775198268\n",
    "r2: 0.8486882566011\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
