{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Methods\n",
    "\n",
    "\n",
    "> \"Linear models for reinforcement learning\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [linear-model, reinforcement-learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a> Linear methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, we will continue our function approximation journey by introducing linear models for representing the state value function $V_{\\pi}(S_t)$. Recall that in the case of large state spaces it is advantageous to use some sort of parametic funtion approximation rather than a tabular representation of the state value function. Furthermore, we need a model in order to to perform, for examle, the SGD update step given below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{w}_{t+1}  = \\mathbf{w}_t + \\eta \\left[V_{\\pi}(S_t)-\\hat{V}_{\\pi}(S_t,\\mathbf{w}_t) \\right ] \\nabla \\hat{V}(S_t, \\mathbf{w}_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest representations we can have, and the one we take in this post,  is a linear model with resepct to the weights $\\mathbf{w}$. In this case, $\\hat{V}(s, \\mathbf{w})$ becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{V}(s, \\mathbf{w}) = \\sum_{i=1}^{d} w_i x_i(s) = \\mathbf{w}^T \\mathbf{x}(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression above implies that there is a vector $\\mathbf{x}(s)$ for every state having the same number of components as the weights vector. The vector $\\mathbf{x}(s)$ represents the features of the state $s$. For example for an autonomous vehicle, $\\mathbf{x}(s)$ may correspond to the vector with components such as vehicle velocity, vehicle acceleration, vehicle position, vehicle orientatio, gas level e.t.c. Technically, each component $x_i$ represents a function such that $x_i: \\mathbb{S}\\rightarrow \\mathbb{R}$ [1]. \n",
    "For linear methods, features are basis functions because they form a linear basis for the set of approximate\n",
    "functions [1]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models have a straightforward gradient calculation. Indeed in this case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla \\hat{V}(S_t, \\mathbf{w}_t) = \\mathbf{x}(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the SGD update step becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{w}_{t+1}= \\mathbf{w}_t + \\eta \\left[V_{\\pi}(S_t)-\\hat{V}_{\\pi}(S_t,\\mathbf{w}_t) \\right ] \\mathbf{x}(S_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are, in general, very well understood throughout science. For our case, when using a linear model case there is only one optimum. Therefore, any method that is guaranteed to converge to or near a local optimum is automatically guaranteed to converge to or near the global\n",
    "optimum [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final note, observe that we need $V_{\\pi}(S_t)$ in order to perform SGD weights update. This many not always be available. We may, however, have in hand an approximation of it, let's calle it $U_t$ i.e. $V_{\\pi}(S_t) \\approx U_t$. In this scenario, we are forced to use the latter. However, if $U_t$ is an unbiasd estimate, then $\\mathbf{w}_t$ is guaranteed to converge to a local optimum under the conditions specified above for decreasing $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Richard S. Sutton and Andrew G. Barto, ```Reinforcement Learning: An Introduction```. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
