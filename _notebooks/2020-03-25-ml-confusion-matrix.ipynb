{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notes. Confusion Matrix\n",
    "\n",
    ">' Using confusion matrix to assess a classifier'\n",
    "\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- author: Alexandros Giavaras\n",
    "- categories: [machine-learning, confusion-matrix, classifier-assessment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than often, we want to evaluate the performance of a classifier. This can be summarised by using a table knowm as **contingency table** or <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">confusion matrix</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a> Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table where each row refers to actual classes as recorder in the test set, and each column to classes as predicted by the classifier. When we have the confusion matrix computed, we can extract various perormance metrics. We will illustrate this with an example concerning two-class classification. Most, however not all, of the metrics can easilly be extended to more than two classes classification. The following table summarizes various metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"test_case_1\"></a> Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is perhaps the simplest of the metrics we can compute [2]. It is defined s the proportion of correctly classified instances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy} = \\frac{\\text{Number of correctly classified examples}}{\\text{Total number of examples}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define the **error rate** as the proportion of incorrectly classified insrances. Clearly, this will be given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Error rate} = 1 - \\text{accuracy}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, we can view accuracy as an estimate of the probability that an arbitrary instance $\\mathbf{x}\\in \\mathbf{X}$ is classified correctly i.e. as the probability [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\hat{c}(\\mathbf{x}) = c(\\mathbf{x})| \\hat{f})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Confusion matrix</a>\n",
    "2. Peter Flach, ```Machine Learning The Art and Science of Algorithms that Make Sense of Data```, Cambridge Press"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
