<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Apache Spark. Create an RDD with Scala | qubit-computing</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Apache Spark. Create an RDD with Scala" />
<meta name="author" content="Alexandros Giavaras" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Create an RDD with Scala" />
<meta property="og:description" content="Create an RDD with Scala" />
<link rel="canonical" href="https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/08/19/spark-rdd-scala.html" />
<meta property="og:url" content="https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/08/19/spark-rdd-scala.html" />
<meta property="og:site_name" content="qubit-computing" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-08-19T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/08/19/spark-rdd-scala.html","@type":"BlogPosting","headline":"Apache Spark. Create an RDD with Scala","dateModified":"2021-08-19T00:00:00-05:00","datePublished":"2021-08-19T00:00:00-05:00","author":{"@type":"Person","name":"Alexandros Giavaras"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/08/19/spark-rdd-scala.html"},"description":"Create an RDD with Scala","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/qubit_opus/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://pockerman.github.io/qubit_opus/feed.xml" title="qubit-computing" /><link rel="shortcut icon" type="image/x-icon" href="/qubit_opus/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/qubit_opus/">qubit-computing</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/qubit_opus/about/">About Me</a><a class="page-link" href="/qubit_opus/projects/">Projects</a><a class="page-link" href="/qubit_opus/search/">Search</a><a class="page-link" href="/qubit_opus/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Apache Spark. Create an RDD with Scala</h1><p class="page-description">Create an RDD with Scala</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-08-19T00:00:00-05:00" itemprop="datePublished">
        Aug 19, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Alexandros Giavaras</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/qubit_opus/categories/#spark">spark</a>
        &nbsp;
      
        <a class="category-tags-link" href="/qubit_opus/categories/#scala">scala</a>
        &nbsp;
      
        <a class="category-tags-link" href="/qubit_opus/categories/#big-data">big-data</a>
        &nbsp;
      
        <a class="category-tags-link" href="/qubit_opus/categories/#data-engineering">data-engineering</a>
        &nbsp;
      
        <a class="category-tags-link" href="/qubit_opus/categories/#data-analysis">data-analysis</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#-Overview"> Overview </a></li>
<li class="toc-entry toc-h2"><a href="#The-RDD-abstraction">The RDD abstraction </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Create-Spark-RDD-with-Scala">Create Spark RDD with Scala </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Other-methods">Other methods </a></li>
<li class="toc-entry toc-h2"><a href="#Transformations-and-actions">Transformations and actions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Transformations">Transformations </a></li>
<li class="toc-entry toc-h3"><a href="#Actions">Actions </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Summary">Summary </a></li>
<li class="toc-entry toc-h2"><a href="#References">References </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-08-19-spark-rdd-scala.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="-Overview">
<a class="anchor" href="#-Overview" aria-hidden="true"><span class="octicon octicon-link"></span></a><a name="overview"></a> Overview<a class="anchor-link" href="#-Overview"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In post <a href="https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/07/06/spark-application-concepts.html">Apache Spark. Application concepts</a> we went over some basic but core concepts associated with Spark. In this post, we will introduce the most basic abstraction in Spark namely the RDD (or the Resilient Distributed Dataset) [2].   Although, modern applications most likely will be using the <code>DataFrame</code> and/or <code>DataSet</code> APIs, still the RDD data structure is what lies underneath the latter two and therefore always useful to know. Moreover, in this post we will see how to create a Spark RDD within a Scala application. As we will see, there are various methods to create an RDD in Spark. The following example is taken for <a href="https://sparkbyexamples.com/apache-spark-rdd/how-to-create-an-rdd-using-parallelize/">Spark by {Examples}</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can find the example snippets at <a href="https://github.com/pockerman/comp_stats_scala">Computational Statistics with Scala</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-RDD-abstraction">
<a class="anchor" href="#The-RDD-abstraction" aria-hidden="true"><span class="octicon octicon-link"></span></a>The RDD abstraction<a class="anchor-link" href="#The-RDD-abstraction"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The RDD is perhaps the most basic abstraction in Spark. An RDD is an immutable collection of objects that can be distributed across a cluster of computers. An RDD collection is divided into a number of partitions so that each node on a Spark cluster  can independently perform computations. There are three concepts associated with an RDD [2]:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Dependencies</li>
<li>Partitions</li>
<li>Compute function</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Partitions provide the ability to split the work and therefore to parallelize computation across executors. The compute function produces the data that will be stored in the RDD. Finally the dependencies, inform Spark how an RDD is constructed. This allows for RDD resiliency as Spark, if needed, is able to recreate the RDD from the dependencies [2].</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a very simplified overview of what an RDD is, let's how we can create one.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Spark-RDD-with-Scala">
<a class="anchor" href="#Create-Spark-RDD-with-Scala" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create Spark RDD with Scala<a class="anchor-link" href="#Create-Spark-RDD-with-Scala"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two main methods available in Spark to create an RDD:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<code>SparkContext.parallelize</code> method</li>
<li>Read from a file</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first method is illustrated in the code listing example below</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>package train.spark

import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object CreateRDD {
  def main(args: Array[String]) {

    val conf = new SparkConf().setAppName("Hello Spark RDD")
    val sc = new SparkContext(conf)

    val data = Array(1,2,3,4,5,6,7,8,9,10)
    val rdd = sc.parallelize(data)
    rdd.foreach(println)

    println("Number of Partitions: "+rdd.getNumPartitions)
    println("Action: First element: "+rdd.first()) 
  }
}</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Running the application produces something like the following</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>3
6
1
8
9
2
7
4
5
10
Number of Partitions: 4
Action: First element: 1</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note the the output may be different as it depends on which thread is accessing  the standard output first.
Note that the application above has to create a <code>SparkContext</code> first before we are able to create an RDD.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><strong>Remark</strong></p>
<p>Creating a <code>SparkContext</code> is not necessary when we use the Spark shell as one such object is already created for us.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The second method is to read a file from disk. This is also shown in the snippet below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>package train.spark

import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object CreateRDDFile {
  def main(args: Array[String]) {

    val conf = new SparkConf().setAppName("Hello Spark RDD")
    val sc = new SparkContext(conf)

    // Should be some file on your system
    val csvFile = "/home/alex/qi3/learn_scala/scripts/spark/data/train.csv" 
    val csvRDD = sc.textFile(csvFile)

    println("Number of Partitions: "+csvRDD.getNumPartitions)

    // prints the header of the file
    println("Action: First element: "+csvRDD.first()) 
  }
}</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Upon executing this code, we get</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>Number of Partitions: 2
Action: First element: #Duplicate: 0, Delete: 1, Normal-1: 2, TUF: 3, Normal-2: 4</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>However, we are interested in converting the contents of the file into floating point numbers so that we can feed them to a machine learning algorithm. We can do this as follows.  we can use the <code>map()</code> function to convert the <code>RDD[String]</code> into an <code>RDD[Array[Double]]</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>val doubleRDD = csvRDD.map(line =&gt; {line.split(",")})
                      .map( arrString =&gt; {Try(Array(arrString(0).toDouble, arrString(1).toDouble,                                                                   arrString(2).toDouble))})
                      .map(_ match {case Success(res) =&gt; res
                                         case Failure(res) =&gt; Array(-100, -100, -100)})</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also use a schema in order to let Spark know the type of the data but this requires that we use a <code>DataFrame</code> instead and not an RDD.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note also that Spark divides by default data into two partitions and distributes them across a cluster. The number of partitions can be specified while creating an RDD as shown below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>object CreateRDDFile {
  def main(args: Array[String]) {

    ...

    // Should be some file on your system
    val csvFile = "/home/alex/qi3/learn_scala/scripts/spark/data/train.csv" 
    val csvRDD = sc.textFile(csvFile, 4)

    ...
  }
}</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Other-methods">
<a class="anchor" href="#Other-methods" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other methods<a class="anchor-link" href="#Other-methods"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As an aside, we can create an RDD by using the following also:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>JDBC</li>
<li>Cassandra</li>
<li>HBase</li>
<li>Elasticsearch</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transformations-and-actions">
<a class="anchor" href="#Transformations-and-actions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transformations and actions<a class="anchor-link" href="#Transformations-and-actions"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In <a href="https://pockerman.github.io/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/07/06/spark-application-concepts.html">Apache Spark. Application concepts</a> we introduced the two types of operations one can apply on an RDD namely transformations and actions [1]. 
You can find more information on these two operations in <a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html">RDD Programming Guide</a>. Below we just give a brief overview of what each operation entails.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transformations">
<a class="anchor" href="#Transformations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transformations<a class="anchor-link" href="#Transformations"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Transformations in Spark transform a <code>DataFrame</code> into a new one. This is done without altering the original data. Hence a transformation is an immutable operation as far as the original data is concerned. Some examples of transformations are listed below [3]</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<code>map(function)</code>: It returns a new data set by operating on each element of the source RDD.</li>
<li>
<code>flatMap(function)</code>: Similar to map, but each item can be mapped to zero, one, or more items.</li>
<li>
<code>mapPartitions(function)</code>: Similar to map, but works on the partition level.</li>
<li>
<p><code>mapPartitionsWithIndex(function)</code>: Similar to <code>mapPartitions</code>, but provides a function with an Int value to indicate the index position of the partition.</p>
</li>
<li>
<p><code>filter(function)</code>: It returns a new RDD that contains only elements that satisfy the predicate.</p>
</li>
<li>
<p><code>union(otherDataset)</code>: It returns a new data set that contains the elements of the source RDD and the <code>otherDataset</code>  RDD. Note that the participating RDDs should be of the same data type.</p>
</li>
<li>
<p><code>intersection(otherDataset)</code>: It returns a new data set that contains the intersection of elements from the source RDD and the argument RDD.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Actions">
<a class="anchor" href="#Actions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Actions<a class="anchor-link" href="#Actions"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An action triggers the lazy evaluation of all the recorded transformations [1]. A list of actions is given below [3].</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<code>collect()</code>: Returns all the elements of the data set are returned as an array to the driver program.</li>
<li>
<code>count()</code>:  Returns the number of elements in the data set.</li>
<li>
<p><code>reduce(function)</code>: It returns a data set by aggregating the elements of the RDD it is applied on. The aggregation is done by using  the user provided <code>function</code> argument. The <code>function</code> should take two arguments and returns a single argument. Moreover it should be commutative and associative so that it can be operated in parallel.</p>
</li>
<li>
<p><code>first()</code>: Returns the first element in the data set.</p>
</li>
<li>
<code>take(n)</code>: Returns the first <code>n</code> elements in the data set as an array.</li>
<li>
<code>takeOrdered(n, [ordering])</code>: Return the first <code>n</code>  elements of the RDD using either their natural order or a custom comparator.</li>
<li>
<code>takeSample(withReplacement, num, [seed])</code>: Returns an array with a random sample of num elements of the dataset, with or without replacement, optionally pre-specifying a random number generator seed.</li>
<li>
<code>saveAsTextFile(path)</code>: Write the elements of the RDD as a text file in the local file system, HDFS, or any another supported storage system.</li>
<li>
<code>foreach(function)</code>: Applies the <code>function</code> argument on each element in the RDD.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">
<a class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary<a class="anchor-link" href="#Summary"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this post we saw how to create an RDD in Spark application. Specifically, there are two ways to do so; using the <code>SparkContext.parallelize</code> function and reading from a file. RDDs are now considered as low level Spark programming. Moreover, we reiterated over the concept of transformations and actions and we saw some non-exclusive examples of both.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html">RDD Programming Guide</a></li>
<li>Jules S. Damji, Brooke Wenig, Tathagata Das, Deny Lee, <em>Learning Spark. Lighting-fasts data analytics</em>, 2nd Edition, O'Reilly.</li>
<li>Subhashini Chellappan, Dharanitharan Ganesan, <em>Practical Apache Spark. Using the Scala API</em>, Apress</li>
</ol>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/qubit_opus/spark/scala/big-data/data-engineering/data-analysis/2021/08/19/spark-rdd-scala.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/qubit_opus/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/qubit_opus/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/qubit_opus/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Computing is fun (most of the times...)</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/pockerman" target="_blank" title="pockerman"><svg class="svg-icon grey"><use xlink:href="/qubit_opus/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
